{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Capelin\\virtual-envs\\.venv-diarization\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "e:\\Capelin\\virtual-envs\\.venv-diarization\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n",
      "train_logger.py     :264  2024-07-13 14:07:14,324 torchvision is not available - cannot save figures\n"
     ]
    }
   ],
   "source": [
    "import runpod\n",
    "import whisperx\n",
    "import base64\n",
    "import json\n",
    "import tempfile\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url):\n",
    "    \"\"\"\n",
    "    Download a file from a URL to a temporary file and return its path.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\"Failed to download file from URL\")\n",
    "\n",
    "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')\n",
    "    temp_file.write(response.content)\n",
    "    temp_file.close()\n",
    "    return temp_file.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deallocate_gpu_memory_if_low(model:object=None) -> None:\n",
    "    \"\"\"Delete model if low on GPU resources\"\"\"\n",
    "    import torch\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.cuda.current_device()\n",
    "\n",
    "        # Get the total and used memory in bytes\n",
    "        total_mem = torch.cuda.get_device_properties(device).total_memory\n",
    "        used_mem = torch.cuda.memory_allocated(device)\n",
    "\n",
    "        # Convert the memory size to GB\n",
    "        total_mem_gb = total_mem / (1024 * 1024 * 1024)\n",
    "        used_mem_gb = used_mem / (1024 * 1024 * 1024)\n",
    "\n",
    "        # Calculate remaining memory\n",
    "        remaining_mem_gb = total_mem_gb - used_mem_gb\n",
    "        remaining_mem_percent = remaining_mem_gb / total_mem_gb * 100\n",
    "        print(\n",
    "            f\"GPU memory: Total {total_mem_gb:.2f}GB, Used {used_mem_gb:.2f}GB, Remaining {remaining_mem_gb:.2f}GB ({remaining_mem_percent:.2f}%)\",\n",
    "        )\n",
    "\n",
    "        if remaining_mem_percent <= 50:\n",
    "            print(\n",
    "                f\"Clearing up GPU memory. {used_mem_gb:.1f}GB of {total_mem_gb:.2f}GB used, {remaining_mem_percent:.1f}% remaining.\",\n",
    "            )\n",
    "            import gc\n",
    "\n",
    "            import torch\n",
    "\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            if model:\n",
    "                del model\n",
    "\n",
    "\n",
    "def check_gpu_availability() -> bool:\n",
    "    import torch\n",
    "\n",
    "    return torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_huggingface_token() -> str:\n",
    "    return os.environ.get(\"HF_TOKEN\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def temp_envvar(envvar_name: str, value: str) -> None:\n",
    "    \"\"\"\n",
    "    Set an environment variable temporarily for the duration of a `with` block\n",
    "\n",
    "    Args:\n",
    "    ----\n",
    "        key (str): environment variable name\n",
    "        value (str): value to set the environment variable to\n",
    "\n",
    "    \"\"\"\n",
    "    original_value = os.environ.get(envvar_name)\n",
    "    os.environ[envvar_name] = value\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        if original_value is None:\n",
    "            del os.environ[envvar_name]\n",
    "        else:\n",
    "            os.environ[envvar_name] = original_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class Transcript(Enum):\n",
    "    DIARIZED = \"diarized_transcription\"\n",
    "    SPEAKER = \"speaker\"\n",
    "    SEGMENTS = \"segments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16 # reduce if low on GPU mem\n",
    "language_code = \"en\"\n",
    "\n",
    "def base64_to_tempfile(base64_data):\n",
    "    \"\"\"\n",
    "    Decode base64 data and write it to a temporary file.\n",
    "    Returns the path to the temporary file.\n",
    "    \"\"\"\n",
    "    # Decode the base64 data to bytes\n",
    "    audio_data = base64.b64decode(base64_data)\n",
    "\n",
    "    # Create a temporary file and write the decoded data\n",
    "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')\n",
    "    with open(temp_file.name, 'wb') as file:\n",
    "        file.write(audio_data)\n",
    "\n",
    "    return temp_file.name\n",
    "\n",
    "def get_settings() -> tuple[str, str]:\n",
    "    # device = \"cuda\"\n",
    "    # batch_size = 16 # reduce if low on GPU mem\n",
    "    # compute_type = \"float16\" # change to \"int8\" if low on GPU mem (may reduce accuracy)\n",
    "\n",
    "    if check_gpu_availability():\n",
    "        return \"cuda\", \"float16\"\n",
    "\n",
    "    return \"cpu\", \"int8\"\n",
    "\n",
    "def handler(event):\n",
    "    \"\"\"\n",
    "    Run inference on the model.\n",
    "\n",
    "    Args:\n",
    "        event (dict): The input event containing the audio data.\n",
    "            The event should have the following structure:\n",
    "            {\n",
    "                \"input\": {\n",
    "                    \"audio_base_64\": str,  # Base64-encoded audio data (optional)\n",
    "                    \"audio_url\": str       # URL of the audio file (optional)\n",
    "                }\n",
    "            }\n",
    "            Either \"audio_base_64\" or \"audio_url\" must be provided.\n",
    "    \"\"\"\n",
    "    job_input = event['input']\n",
    "    job_input_audio_base_64 = job_input.get('audio_base_64')\n",
    "    job_input_audio_url = job_input.get('audio_url')\n",
    "\n",
    "    if job_input_audio_base_64:\n",
    "        # If there is base64 data\n",
    "        audio_input = base64_to_tempfile(job_input_audio_base_64)\n",
    "    elif job_input_audio_url and job_input_audio_url.startswith('http'):\n",
    "        # If there is an URL\n",
    "        audio_input = download_file(job_input_audio_url)\n",
    "    else:\n",
    "        return json.dumps({\"error\": \"Invalid audio\"}, indent=4)\n",
    "    \n",
    "    model_files_root = \"../models\"\n",
    "\n",
    "    try:\n",
    "        deallocate_gpu_memory_if_low()\n",
    "        device, compute_type = get_settings()\n",
    "\n",
    "        audio = whisperx.load_audio(audio_input)\n",
    "\n",
    "        model = whisperx.load_model(\n",
    "              \"large-v2\",\n",
    "              device,\n",
    "              compute_type=compute_type,\n",
    "              download_root=model_files_root,\n",
    "              asr_options={\n",
    "                  \"word_timestamps\": False,  # set to True if you want word timestamps\n",
    "                  \"max_new_tokens\": None,\n",
    "                  \"clip_timestamps\": None,\n",
    "                  \"hallucination_silence_threshold\": None,\n",
    "              },\n",
    "          )\n",
    "        \n",
    "        result = model.transcribe(audio, batch_size=batch_size, language=\"en\")\n",
    "        \n",
    "        deallocate_gpu_memory_if_low([model])\n",
    "\n",
    "        model_a, metadata = whisperx.load_align_model(\n",
    "              language_code=result[\"language\"],\n",
    "              device=device,\n",
    "              model_dir=model_files_root,\n",
    "          )\n",
    "        \n",
    "        resulta = whisperx.align(\n",
    "              result[\"segments\"],\n",
    "              model_a,\n",
    "              metadata,\n",
    "              audio,\n",
    "              device,\n",
    "              return_char_alignments=False,\n",
    "          )\n",
    "        \n",
    "        deallocate_gpu_memory_if_low(model_a)\n",
    "\n",
    "        with temp_envvar(\"PYANNOTE_CACHE\", model_files_root):\n",
    "            # Can add min/max number of speakers if known\n",
    "            # diarize_model(audio, min_speakers=min_speakers, max_speakers=max_speakers)\n",
    "            hf_token = get_huggingface_token()\n",
    "            diarize_model = whisperx.DiarizationPipeline(\n",
    "                use_auth_token=hf_token, device=device,\n",
    "            )\n",
    "\n",
    "        diarize_segments = diarize_model(audio)\n",
    "        result_diarized = whisperx.assign_word_speakers(diarize_segments, resulta)\n",
    "\n",
    "        deallocate_gpu_memory_if_low(diarize_model)\n",
    "        del result_diarized[\"word_segments\"]\n",
    "        return json.dumps(result_diarized, indent=4)\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"Error in diarizing: {str(e)}\"}, indent=4)\n",
    "\n",
    "# runpod.serverless.start({\n",
    "#     \"handler\": handler\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_path = \"./yt-0pyalp198h8_SpPFdmXj.mp3\"\n",
    "# convert it to base 64\n",
    "\n",
    "with open(audio_file_path, \"rb\") as file:\n",
    "    audio_base64 = base64.b64encode(file.read()).decode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "                \"input\": {\n",
    "                    \"audio_base_64\": audio_base64,  # Base64-encoded audio data (optional)\n",
    "                }\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = handler(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-diarization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
